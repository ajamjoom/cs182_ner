{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 281837: expected 25 fields, saw 34\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 24)\n",
      "(16000,)\n",
      "30172\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"ner.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False)\n",
    "data.head()\n",
    "# drop null rows and check if any null values remaining\n",
    "data.dropna(inplace=True)\n",
    "data[data.isnull().any(axis=1)].size\n",
    "\n",
    "data_small = data[:20000]\n",
    "data_valid = data[20000:30000]\n",
    "\n",
    "preds = list(data.columns.values)\n",
    "preds.remove('tag')\n",
    "y_small = data_small['tag']\n",
    "x_small = data_small[preds]\n",
    "\n",
    "# Split into train and test data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_small, y_small, test_size=0.2, random_state=0)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "pos_list = list(set(data['pos']))\n",
    "shape_list = list(set(data['shape']))\n",
    "word_list = list(set(data['word']))\n",
    "tag_list = list(set(data['tag'].values))\n",
    "\n",
    "print(len(word_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'I-art': 0.0011, u'B-nat': 0.00045, u'B-gpe': 0.02535, u'B-art': 0.00185, u'I-tim': 0.0025, u'B-org': 0.01895, u'I-per': 0.01775, u'B-geo': 0.02555, u'I-org': 0.01395, u'I-geo': 0.00395, u'O': 0.8556, u'I-eve': 0.0007, u'B-eve': 0.0009, u'I-gpe': 0.0013, u'B-tim': 0.0156, u'I-nat': 0.00025, u'B-per': 0.01425}\n",
      "()\n",
      "BASELINE ALL 'O' CLASSIFIER\n",
      "Accuracy Score: 0.8556\n",
      "F1 Score: 0.789018495365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# INITIAL STATE PROBABILITIES\n",
    "\n",
    "initial_tag_probs = {}\n",
    "\n",
    "for tag in tag_list:\n",
    "    prob = 1.0*len(data_small[data_small['tag'] == tag]) / len(data_small)\n",
    "    initial_tag_probs[tag] = prob\n",
    "    \n",
    "print(initial_tag_probs)\n",
    "\n",
    "pred_b = []\n",
    "for i in range(len(data_small)):\n",
    "    pred_b.append('O')\n",
    "    \n",
    "print()\n",
    "print(\"BASELINE ALL 'O' CLASSIFIER\")\n",
    "print(\"Accuracy Score: \" + str(accuracy_score(data_small['tag'], pred_b)))\n",
    "print(\"F1 Score: \" + str(f1_score(data_small['tag'], pred_b, labels=tag_list, average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRANSITION PROBABILITIES, from tag to tag\n",
    "\n",
    "transition_probs = {}\n",
    "for tag1 in tag_list:\n",
    "    within_tag = {}\n",
    "    data_tag1 = data_small[data_small['tag'] == tag1]\n",
    "    for tag2 in list(set(data_small['prev-iob'])):\n",
    "        to_tag2 = data_tag1[data_tag1['prev-iob'] == tag2]\n",
    "        within_tag[tag2] = len(to_tag2)*1.0/len(data_tag1)\n",
    "    transition_probs[tag1] = within_tag\n",
    "\n",
    "# remake with a very small amount of hallucination\n",
    "alpha = 0.01\n",
    "\n",
    "transition_probs2 = {}\n",
    "for tag1 in tag_list:\n",
    "    within_tag = {}\n",
    "    data_tag1 = data_small[data_small['tag'] == tag1]\n",
    "    for tag2 in tag_list:\n",
    "        to_tag2 = data_tag1[data_tag1['prev-iob'] == tag2]\n",
    "        within_tag[tag2] = (alpha + len(to_tag2)*1.0)/(len(data_tag1) + alpha*len(tag_list))\n",
    "    transition_probs2[tag1] = within_tag\n",
    "    \n",
    "#print(transition_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EMISSION PROBABILITIES (this is the part we will use ML for)\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "word_emission_probs = {}\n",
    "for word in list(set(data_small['word'])):\n",
    "    word_data = data_small[data_small['word'] == word]\n",
    "    tag_probs = {}\n",
    "    for tag in tag_list:\n",
    "        tag_data = word_data[word_data['tag'] == tag]\n",
    "        prob = (alpha + 1.0*len(tag_data) / (len(word_data) + alpha*len(tag_list)))\n",
    "        tag_probs[tag] = prob\n",
    "    word_emission_probs[word] = tag_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "\n",
    "pos_emission_probs = {}\n",
    "for pos in pos_list:\n",
    "    pos_data = data_small[data_small['pos'] == pos]\n",
    "    tag_probs = {}\n",
    "    for tag in tag_list:\n",
    "        tag_data = pos_data[pos_data['tag'] == tag]\n",
    "        prob = (alpha + 1.0*len(tag_data) / (len(pos_data) + alpha*len(tag_list)))\n",
    "        tag_probs[tag] = prob\n",
    "    pos_emission_probs[word] = tag_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "\n",
    "shape_emission_probs = {}\n",
    "for shape in shape_list:\n",
    "    shape_data = data_small[data_small['shape'] == shape]\n",
    "    tag_probs = {}\n",
    "    for tag in tag_list:\n",
    "        tag_data = shape_data[shape_data['tag'] == tag]\n",
    "        prob = (alpha + 1.0*len(tag_data) / (len(shape_data) + alpha*len(tag_list)))\n",
    "        tag_probs[tag] = prob\n",
    "    shape_emission_probs[word] = tag_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFYING TAG --> POS\n",
      "Train Acc: 0.25735\n",
      "Valid Acc: 0.2623\n",
      "CLASSIFYING TAG --> WORD\n",
      "Train Acc: 0.06225\n",
      "Valid Acc: 0.0596\n",
      "CLASSIFYING TAG --> SHAPE\n",
      "Train Acc: 0.83445\n",
      "Valid Acc: 0.8215\n"
     ]
    }
   ],
   "source": [
    "# ML section, takes in tag and returns feature prediction\n",
    "\n",
    "# predictors, one hot encode for training\n",
    "predictor = data_small['tag']\n",
    "pred_final = pd.get_dummies(predictor)\n",
    "\n",
    "response_1 = data_small['word']\n",
    "response_2 = data_small['pos']\n",
    "response_3 = data_small['shape']\n",
    "\n",
    "classify = RandomForestClassifier()\n",
    "classify.fit(pred_final, response_2)\n",
    "pred = classify.predict(pred_final)\n",
    "print(\"CLASSIFYING TAG --> POS\")\n",
    "print(\"Train Acc: \" + str(accuracy_score(pred, response_2)))\n",
    "pred2 = classify.predict(pd.get_dummies(data_valid['tag']))\n",
    "print(\"Valid Acc: \" + str(accuracy_score(pred2, data_valid['pos'])))\n",
    "\n",
    "\n",
    "classify2 = RandomForestClassifier()\n",
    "classify2.fit(pred_final, response_1)\n",
    "pred = classify2.predict(pred_final)\n",
    "print(\"CLASSIFYING TAG --> WORD\")\n",
    "print(\"Train Acc: \" + str(accuracy_score(pred, response_1)))\n",
    "pred2 = classify2.predict(pd.get_dummies(data_valid['tag']))\n",
    "print(\"Valid Acc: \" + str(accuracy_score(pred2, data_valid['word'])))\n",
    "\n",
    "classify3 = RandomForestClassifier()\n",
    "classify3.fit(pred_final, response_3)\n",
    "pred = classify3.predict(pred_final)\n",
    "print(\"CLASSIFYING TAG --> SHAPE\")\n",
    "print(\"Train Acc: \" + str(accuracy_score(pred, response_3)))\n",
    "pred2 = classify3.predict(pd.get_dummies(data_valid['tag']))\n",
    "print(\"Valid Acc: \" + str(accuracy_score(pred2, data_valid['shape'])))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B-art</th>\n",
       "      <th>B-eve</th>\n",
       "      <th>B-geo</th>\n",
       "      <th>B-gpe</th>\n",
       "      <th>B-nat</th>\n",
       "      <th>B-org</th>\n",
       "      <th>B-per</th>\n",
       "      <th>B-tim</th>\n",
       "      <th>I-art</th>\n",
       "      <th>I-eve</th>\n",
       "      <th>I-geo</th>\n",
       "      <th>I-gpe</th>\n",
       "      <th>I-nat</th>\n",
       "      <th>I-org</th>\n",
       "      <th>I-per</th>\n",
       "      <th>I-tim</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B-art  B-eve  B-geo  B-gpe  B-nat  B-org  B-per  B-tim  I-art  I-eve  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0   \n",
       "1      0      0      0      0      0      0      0      0      0      0   \n",
       "2      0      0      0      0      0      0      0      0      0      0   \n",
       "3      0      0      0      0      0      0      0      0      0      0   \n",
       "4      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   I-geo  I-gpe  I-nat  I-org  I-per  I-tim  O  \n",
       "0      0      0      0      0      0      0  1  \n",
       "1      0      0      0      0      0      0  1  \n",
       "2      0      0      0      0      0      0  1  \n",
       "3      0      0      0      0      0      0  1  \n",
       "4      0      0      0      0      0      0  1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = data_small['tag']\n",
    "pred_final = pd.get_dummies(predictor)\n",
    "pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_B-art</th>\n",
       "      <th>0_B-eve</th>\n",
       "      <th>0_B-geo</th>\n",
       "      <th>0_B-gpe</th>\n",
       "      <th>0_B-nat</th>\n",
       "      <th>0_B-org</th>\n",
       "      <th>0_B-per</th>\n",
       "      <th>0_B-tim</th>\n",
       "      <th>0_I-art</th>\n",
       "      <th>0_I-eve</th>\n",
       "      <th>0_I-geo</th>\n",
       "      <th>0_I-gpe</th>\n",
       "      <th>0_I-nat</th>\n",
       "      <th>0_I-org</th>\n",
       "      <th>0_I-per</th>\n",
       "      <th>0_I-tim</th>\n",
       "      <th>0_O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_B-art  0_B-eve  0_B-geo  0_B-gpe  0_B-nat  0_B-org  0_B-per  0_B-tim  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        1        0        0        0        0   \n",
       "2        1        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   0_I-art  0_I-eve  0_I-geo  0_I-gpe  0_I-nat  0_I-org  0_I-per  0_I-tim  0_O  \n",
       "0        1        0        0        0        0        0        0        0    0  \n",
       "1        0        0        0        0        0        0        0        0    0  \n",
       "2        0        0        0        0        0        0        0        0    0  \n",
       "3        0        0        0        0        0        0        1        0    0  \n",
       "4        0        0        0        0        0        0        0        1    0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.get_dummies(pd.DataFrame(tag_list))\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'PRP$': 0.0089220369693593458, u'VBG': 0.021212983413126614, u'VBD': 0.043422368456786112, u'``': 0.003913410978814722, u'VBN': 0.036630834286552519, u',': 0.03353431476800374, u'VBP': 0.020815102977365812, u'WDT': 0.0032597265065999019, u'JJ': 0.068888722474133357, u'WP': 0.0024248124350451567, u'VBZ': 0.027569796022639249, u'DT': 0.11161884561362109, u'RP': 0.0026228080561461944, u'$': 0.0013434493480027013, u'NN': 0.15877304924469465, u'POS': 0.010930919799457352, u'.': 0.053138638223153532, u'TO': 0.025726521829419112, u'PRP': 0.018806379996655034, u'RB': 0.022685700421624953, u';': 9.3578874612571824e-05, u':': 0.0010166839485315367, u'NNS': 0.086957967825612298, u'NNP': 0.0016943207104910811, u'VB': 0.028416428758626794, u'WRB': 0.003569436748889797, u'RRB': 0.00061322433632206037, u'CC': 0.024268637460954673, u'PDT': 0.00017515726216841713, u'RBS': 0.00039158358535533889, u'RBR': 0.0012091936537193539, u'CD': 0.021400854735720447, u'NNPS': 7.0016489137145205e-05, u'EX': 0.00092913102391933692, u'IN': 0.13573586689195971, u'WP$': 5.8373619479592858e-05, u'MD': 0.0086934427263483088, u'LRB': 0.00064277799510539346, u'JJS': 0.0038794444991316207, u'JJR': 0.0039434570327133789}\n"
     ]
    }
   ],
   "source": [
    "def features_from_tag(test_data):\n",
    "    response_1 = data_small['word']\n",
    "    response_2 = data_small['pos']\n",
    "    response_3 = data_small['shape']\n",
    "    \n",
    "    predictor = data_small['tag']\n",
    "    pred_final = pd.get_dummies(predictor)\n",
    "    \n",
    "    classify1 = RandomForestClassifier()\n",
    "    classify2 = RandomForestClassifier()\n",
    "    classify3 = RandomForestClassifier()\n",
    "\n",
    "    \n",
    "    classify1.fit(pred_final, response_1)\n",
    "    classify2.fit(pred_final, response_2)\n",
    "    classify3.fit(pred_final, response_3)\n",
    "    \n",
    "    # get likelihoods for each tag\n",
    "    \n",
    "    #for tag in tag_list:\n",
    "    target = pd.get_dummies(pd.DataFrame(tag_list))\n",
    "    #print(list(set(target)))\n",
    "    #target = pd.get_dummies(pd.DataFrame(test_data['tag']))\n",
    "    \n",
    "    p1 = classify1.predict_proba(target)\n",
    "    p2 = classify2.predict_proba(target)\n",
    "    p3 = classify3.predict_proba(target)\n",
    "    \n",
    "    emission_probs = {}\n",
    "    for i in range(len(tag_list)):\n",
    "        word_preds = {}\n",
    "        words = classify1.classes_\n",
    "        for j in range(len(words)):\n",
    "            p = p1[i][j]\n",
    "            word_preds[words[j]] = p\n",
    "            \n",
    "        pos_preds = {}\n",
    "        poss = classify2.classes_\n",
    "        for k in range(len(poss)):\n",
    "            pos_preds[poss[k]] = p2[i][k]\n",
    "        \n",
    "        shape_preds = {}\n",
    "        shapes = classify3.classes_\n",
    "        for l in range(len(shapes)):\n",
    "            shape_preds[shapes[l]] = p3[i][l]\n",
    "        \n",
    "        emission_probs[list(set(data_small['tag']))[i]] = [word_preds, pos_preds, shape_preds]\n",
    "        \n",
    "    return emission_probs, classify1.classes_, classify2.classes_, classify3.classes_\n",
    "    \n",
    "\n",
    "f, final_word_list, final_pos_list, final_shape_list = features_from_tag(data_valid)\n",
    "print(f['O'][1])    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try with knn\n",
    "# doesn't seem to be better than random forest\n",
    "\n",
    "#classify = KNeighborsClassifier(1000)\n",
    "#classify.fit(pred_final, response_2)\n",
    "#pred = classify.predict(pred_final)\n",
    "#print(\"CLASSIFYING TAG --> POS\")\n",
    "#print(\"Train Acc: \" + str(accuracy_score(pred, response_2)))\n",
    "#pred2 = classify.predict(pd.get_dummies(data_valid['tag']))\n",
    "#print(\"Valid Acc: \" + str(accuracy_score(pred2, data_valid['pos'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def viterbi_prediction():\n",
    "    train_prediction = []\n",
    "    sentence_indices = list(set(data_small['sentence_idx']))\n",
    "    \n",
    "    count = 0\n",
    "    #print(f['B-gpe'][2])\n",
    "    #print(f['B-geo'][2])\n",
    "    #print(f['B-per'][2])\n",
    "    for index, row in data_small.iterrows():\n",
    "        word = row['word']\n",
    "        pos = row['pos']\n",
    "        shape = row['shape']\n",
    "        max_tag = 'O'\n",
    "        #print(list(f['O'][1].keys()))\n",
    "        if word in list(f['O'][0].keys()):\n",
    "            if pos in list(f['O'][1].keys()):\n",
    "                if shape in list(f['O'][2].keys()):\n",
    "                    max_prob = -1000000\n",
    "                    max_tag = 'O'\n",
    "                    for tag in tag_list:\n",
    "                        # p(e|x)\n",
    "                        emission = 1.0*f[tag][0][word]*f[tag][1][pos]*f[tag][2][shape] * initial_tag_probs[tag]\n",
    "                \n",
    "                        # transition model\n",
    "                        prev_tag = row['prev-iob']\n",
    "                        transition_prob = transition_probs[tag][prev_tag]\n",
    "                    \n",
    "                        prob = emission * transition_prob\n",
    "                    \n",
    "                        if prob > max_prob:\n",
    "                            max_prob = prob\n",
    "                            max_tag = tag\n",
    "                            if max_tag == 'camelcase':\n",
    "                                count += 1\n",
    "        else: \n",
    "            max_tag = 'O'\n",
    "            max_prob = -1\n",
    "            max_tag = 'O'\n",
    "            for tag in tag_list:\n",
    "                # p(e|x)\n",
    "                emission = 1.0*f[tag][1][pos]*f[tag][2][shape] * initial_tag_probs[tag]\n",
    "                \n",
    "                # transition model\n",
    "                prev_tag = row['prev-iob']\n",
    "                transition_prob = transition_probs[tag][prev_tag]\n",
    "                    \n",
    "                prob = emission * transition_prob\n",
    "            \n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_tag = tag\n",
    "            \n",
    "        train_prediction.append(max_tag)\n",
    "        \n",
    "    print(\"Training Accuracy: \" + str(accuracy_score(train_prediction, data_small['tag'])))\n",
    "    print(\"Training F1 Score: \" + str(f1_score(data_small['tag'], train_prediction, labels=tag_list, average=\"weighted\")))\n",
    "    valid_prediction = []\n",
    "    count = 0\n",
    "    #print(f['B-gpe'][2])\n",
    "    #print(f['B-geo'][2])\n",
    "    #print(f['B-per'][2])\n",
    "    for index, row in data_valid.iterrows():\n",
    "        word = row['word']\n",
    "        pos = row['pos']\n",
    "        shape = row['shape']\n",
    "        max_tag = 'O'\n",
    "        #print(list(f['O'][1].keys()))\n",
    "        if word in list(f['O'][0].keys()):\n",
    "            if pos in list(f['O'][1].keys()):\n",
    "                if shape in list(f['O'][2].keys()):\n",
    "                    max_prob = -1000000\n",
    "                    max_tag = 'O'\n",
    "                    for tag in tag_list:\n",
    "                        # p(e|x)\n",
    "                        emission = 1.0*f[tag][0][word]*f[tag][1][pos]*f[tag][2][shape] * initial_tag_probs[tag]\n",
    "                \n",
    "                        # transition model\n",
    "                        prev_tag = row['prev-iob']\n",
    "                        transition_prob = transition_probs[tag][prev_tag]\n",
    "                    \n",
    "                        prob = emission * transition_prob\n",
    "                    \n",
    "                        if prob > max_prob:\n",
    "                            max_prob = prob\n",
    "                            max_tag = tag\n",
    "                            if max_tag == 'camelcase':\n",
    "                                count += 1\n",
    "        else: \n",
    "            max_tag = 'O'\n",
    "            max_prob = -1\n",
    "            max_tag = 'O'\n",
    "            for tag in tag_list:\n",
    "                # p(e|x)\n",
    "                emission = 1.0*f[tag][1][pos]*f[tag][2][shape] * initial_tag_probs[tag]\n",
    "                \n",
    "                # transition model\n",
    "                prev_tag = row['prev-iob']\n",
    "                transition_prob = transition_probs[tag][prev_tag]\n",
    "                    \n",
    "                prob = emission * transition_prob\n",
    "            \n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_tag = tag\n",
    "            \n",
    "        valid_prediction.append(max_tag)\n",
    "        \n",
    "    print(\"Validation Accuracy: \" + str(accuracy_score(valid_prediction, data_valid['tag'])))\n",
    "    print(\"Validation F1 Score: \" + str(f1_score(data_valid['tag'], valid_prediction, labels=tag_list, average=\"weighted\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9815\n",
      "Training F1 Score: 0.981618788639\n",
      "Validation Accuracy: 0.9334\n",
      "Validation F1 Score: 0.934761335015\n"
     ]
    }
   ],
   "source": [
    "viterbi_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'mixedcase', u'lowercase', u'camelcase', u'uppercase', u'capitalized', u'number', u'abbreviation', u'punct', u'other', u'ending-dot', u'contains-hyphen']\n"
     ]
    }
   ],
   "source": [
    "print(list(set(data_valid['shape'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viterbi_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
