{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS182 Final Project\n",
    "\n",
    "### Named-Entity Recognition using an HMM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that building the tagger will have a large enough scope, especially when you show different approaches/ideas and try to maximize your scores. I am also happy to discuss in person early next week. \n",
    "\n",
    "Regarding your ideas: I am not sure why you want a full Bayes-Net - I believe a HMM+Viterbi is sufficient for the task so I recommend implementing that. Here are slides from CS287 that talk about NER and how to approach the problem: https://cs287.github.io/Lectures/slides/lecture14-search.pdf\n",
    "It could be useful for you to compare the performance between the forward and viterbi algorithm here. \n",
    "\n",
    "When you consider more information, please be wary that HMMs/Bayes-Nets have the Markov assumption. You need to be careful when taking previous and following words into account that you don’t violate that assumption. Depending on the size of your corpus, cross-validation might also not be necessary and a simple train/valid/test split could be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 281837: expected 25 fields, saw 34\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemma</th>\n",
       "      <th>next-lemma</th>\n",
       "      <th>next-next-lemma</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-shape</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-shape</th>\n",
       "      <th>next-word</th>\n",
       "      <th>...</th>\n",
       "      <th>prev-prev-lemma</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-shape</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-shape</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>shape</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thousand</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>...</td>\n",
       "      <td>__start2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>...</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>...</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>...</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>london</td>\n",
       "      <td>NNP</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>...</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     lemma next-lemma next-next-lemma next-next-pos  \\\n",
       "0           0  thousand         of        demonstr           NNS   \n",
       "1           1        of   demonstr            have           VBP   \n",
       "2           2  demonstr       have           march           VBN   \n",
       "3           3      have      march         through            IN   \n",
       "4           4     march    through          london           NNP   \n",
       "\n",
       "  next-next-shape next-next-word next-pos next-shape      next-word ...  \\\n",
       "0       lowercase  demonstrators       IN  lowercase             of ...   \n",
       "1       lowercase           have      NNS  lowercase  demonstrators ...   \n",
       "2       lowercase        marched      VBP  lowercase           have ...   \n",
       "3       lowercase        through      VBN  lowercase        marched ...   \n",
       "4     capitalized         London       IN  lowercase        through ...   \n",
       "\n",
       "  prev-prev-lemma prev-prev-pos prev-prev-shape prev-prev-word   prev-shape  \\\n",
       "0      __start2__    __START2__        wildcard     __START2__     wildcard   \n",
       "1      __start1__    __START1__        wildcard     __START1__  capitalized   \n",
       "2        thousand           NNS     capitalized      Thousands    lowercase   \n",
       "3              of            IN       lowercase             of    lowercase   \n",
       "4        demonstr           NNS       lowercase  demonstrators    lowercase   \n",
       "\n",
       "       prev-word sentence_idx        shape           word tag  \n",
       "0     __START1__          1.0  capitalized      Thousands   O  \n",
       "1      Thousands          1.0    lowercase             of   O  \n",
       "2             of          1.0    lowercase  demonstrators   O  \n",
       "3  demonstrators          1.0    lowercase           have   O  \n",
       "4           have          1.0    lowercase        marched   O  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"entity-annotated-corpus/ner.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop null rows and check if any null values remaining\n",
    "data.dropna(inplace=True)\n",
    "data[data.isnull().any(axis=1)].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible predictive data: [u'pos', u'shape', u'tag', u'prev-lemma', u'prev-prev-lemma', u'next-word', u'next-lemma', 'Unnamed: 0', u'next-next-word', u'lemma', u'prev-prev-iob', u'sentence_idx', u'next-next-pos', u'prev-iob', u'next-shape', u'prev-shape', u'prev-prev-word', u'next-next-shape', u'next-pos', u'prev-prev-pos', u'word', u'prev-pos', u'prev-prev-shape', u'prev-word', u'next-next-lemma']\n",
      "\n",
      "What do all of these mean?\n",
      "\n",
      "Tags: [u'I-art', u'B-gpe', u'B-art', u'I-per', u'I-tim', u'B-org', u'O', u'B-geo', u'B-tim', u'I-geo', u'B-per', u'I-eve', u'B-eve', u'I-gpe', u'I-org', u'I-nat', u'B-nat']\n",
      "\n",
      "What do all of these mean?\n",
      "\n",
      "Length of data set: 1050794\n"
     ]
    }
   ],
   "source": [
    "# SOME EDA\n",
    "print(\"Possible predictive data: \" + str(list(set(data.columns.values))))\n",
    "print\n",
    "print(\"What do all of these mean?\")\n",
    "print\n",
    "print(\"Tags: \" + str(list(set(data.tag))))\n",
    "print\n",
    "print(\"What do all of these mean?\")\n",
    "print\n",
    "print(\"Length of data set: \" + str(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 24)\n",
      "(80000,)\n"
     ]
    }
   ],
   "source": [
    "data_small = data[:100000]\n",
    "data_valid = data[100001:150000]\n",
    "preds = list(data.columns.values)\n",
    "preds.remove('tag')\n",
    "y_small = data_small['tag']\n",
    "x_small = data_small[preds]\n",
    "\n",
    "# Split into train and test data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_small, y_small, test_size=0.2, random_state=0)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'PRP$', u'VBG', u'VBD', u'``', u'VBN', u'POS', u'VBP', u'WDT', u'JJ', u'WP', u'VBZ', u'DT', u'RP', u'$', u'NN', u',', u'.', u'TO', u'PRP', u'RB', u';', u':', u'NNS', u'NNP', u'VB', u'WRB', u'RRB', u'CC', u'PDT', u'RBS', u'RBR', u'CD', u'LRB', u'EX', u'IN', u'WP$', u'MD', u'NNPS', u'JJS', u'JJR', u'UH']\n",
      "\n",
      "[u'mixedcase', u'lowercase', u'camelcase', u'ending-dot', u'capitalized', u'number', u'abbreviation', u'punct', u'other', u'uppercase', u'contains-hyphen']\n",
      "\n",
      "[u'I-art', u'B-gpe', u'B-art', u'I-per', u'I-tim', u'B-org', u'O', u'B-geo', u'B-tim', u'I-geo', u'B-per', u'I-eve', u'B-eve', u'I-gpe', u'I-org', u'I-nat', u'B-nat']\n"
     ]
    }
   ],
   "source": [
    "pos_list = list(set(x_train['pos']))\n",
    "print(pos_list)\n",
    "print\n",
    "shape_list = list(set(x_train['shape']))\n",
    "print(shape_list)\n",
    "print\n",
    "tag_list = list(set(y_train.values))\n",
    "print(tag_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'mixedcase': u'O', u'lowercase': u'O', u'camelcase': u'I-per', u'ending-dot': u'B-per', u'number': u'O', u'capitalized': u'O', u'abbreviation': u'B-geo', u'punct': u'O', u'other': u'O', u'uppercase': u'O', u'contains-hyphen': u'O'}\n",
      "{u'PRP$': u'I-art', u'VBG': u'I-art', u'VBD': u'I-art', u'VBN': u'I-art', u',': u'I-art', u'VBP': u'I-art', u'WDT': u'I-art', u'JJ': u'I-art', u'WP': u'I-art', u'VBZ': u'I-art', u'DT': u'I-art', u'RP': u'I-art', u'$': u'I-art', u'NN': u'I-art', u'POS': u'I-art', u'.': u'I-art', u'TO': u'I-art', u'PRP': u'I-art', u'RB': u'I-art', u';': u'I-art', u':': u'I-art', u'NNS': u'I-art', u'NNP': u'I-art', u'``': u'I-art', u'WRB': u'I-art', u'RRB': u'I-art', u'CC': u'I-art', u'PDT': u'I-art', u'RBS': u'I-art', u'RBR': u'I-art', u'CD': u'I-art', u'NNPS': u'I-art', u'EX': u'I-art', u'IN': u'I-art', u'WP$': u'I-art', u'MD': u'I-art', u'LRB': u'I-art', u'JJS': u'I-art', u'JJR': u'I-art', u'VB': u'I-art', u'UH': u'I-art'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build a dict linking shape to likelihood of each tag\n",
    "\n",
    "shape_probs = {}\n",
    "pos_probs = {}\n",
    "\n",
    "# if X shape, then what is the most likely tag?\n",
    "\n",
    "for shape in shape_list:\n",
    "    tag_prob_list = []\n",
    "    for tag in tag_list:\n",
    "        count = 0\n",
    "        for i in data_small[data_small['shape'] == shape]['tag']:\n",
    "            if i == tag:\n",
    "                count += 1\n",
    "        tag_prob_list.append(1.0*count/len(data_small[data_small['shape'] == shape]))\n",
    "    index = tag_prob_list.index(max(tag_prob_list))\n",
    "        \n",
    "    shape_probs[shape] = tag_list[index]\n",
    "    \n",
    "for pos in pos_list:\n",
    "    tag_prob_list = []\n",
    "    for tag in tag_list:\n",
    "        count = 0\n",
    "        for i in data_small[data_small['shape'] == pos]['pos']:\n",
    "            if i == tag:\n",
    "                count += 1\n",
    "        tag_prob_list.append(1.0*count/(len(data_small[data_small['shape'] == pos])+1))\n",
    "    index = tag_prob_list.index(max(tag_prob_list))\n",
    "        \n",
    "    pos_probs[pos] = tag_list[index]\n",
    "\n",
    "print(shape_probs)\n",
    "print(pos_probs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of data without a tag (Baseline accuracy if we only predict 'O': 0.846952875635\n",
      "Train Accuracy: 0.853\n",
      "Validation Accuracy: 0.854017080342\n"
     ]
    }
   ],
   "source": [
    "pred_train = []\n",
    "pred_valid = []\n",
    "\n",
    "num_O = len(data[data['tag'] == 'O'])\n",
    "percent = 1.0*num_O/len(data)\n",
    "print \"Percent of data without a tag (Baseline accuracy if we only predict 'O': \" + str(percent)\n",
    "\n",
    "# training prediction\n",
    "count_correct = 0\n",
    "for i in range(len(data_small)):\n",
    "    pred_tag = shape_probs[data_small.iloc[i]['shape']]\n",
    "    pred_train.append(pred_tag)\n",
    "    if data_small.iloc[i]['tag'] == pred_tag:\n",
    "        count_correct += 1\n",
    "train_accuracy = 1.0*count_correct / len(data_small)\n",
    "print \"Train Accuracy: \" + str(train_accuracy)\n",
    "\n",
    "# validation prediction\n",
    "count_correct = 0\n",
    "for i in range(len(data_valid)):\n",
    "    pred_tag = shape_probs[data_valid.iloc[i]['shape']]\n",
    "    pred_train.append(pred_tag)\n",
    "    if data_valid.iloc[i]['tag'] == pred_tag:\n",
    "        count_correct += 1\n",
    "train_accuracy = 1.0*count_correct / len(data_valid)\n",
    "print \"Validation Accuracy: \" + str(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
